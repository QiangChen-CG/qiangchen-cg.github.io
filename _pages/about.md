---
permalink: /
title:
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<section id="About">
  <h1>About Me</h1>
<p>Assistant Professor. Jiangxi Provincial Key Laboratory of Multimedia Intelligent Processing.
  </p>
  <p>
     I am a Ph.D. and master's supervisor at the <strong>School of Computer Science and Artificial Intelligence, Jiangxi University of Finance and Economics</strong>. 
    Previously, I was a lecturer at the <strong>School of Software, Nanchang University</strong>, and conducted a visiting study at the 
    <strong>National Key Laboratory of CAD&CG, Zhejiang University</strong>, in 2018.
  </p>
  <p>
    I obtained my Ph.D. in <strong>Control Science and Engineering</strong> from <strong>East China Jiaotong University</strong> and earned both my 
    Master's and Bachelor's degrees in <strong>Software Engineering</strong> from <strong>Nanchang University</strong>.
  </p>
  <p>
    My research interests lie in the interdisciplinary fields of <strong>Virtual Reality (VR) technology</strong>, <strong>Computer Graphics</strong>, and <strong>Computer Animation</strong>.  
    I specialize in large-scale crowd simulation, insect animation, and character simulation. 
    I was mentored by Professor <a href="http://graphics.cs.uh.edu/zdeng/" target="_blank"><strong>Zhigang Deng</strong> </a>
    ( University of Houston) and 
    Professor <a href="http://www.cad.zju.edu.cn/home/jin/" target="_blank"><strong>Xiaogang Jin</strong> </a>
    (National Key Laboratory of CAD&CG, Zhejiang University).
  </p>
</section>

<section id="ProspectiveStudents">
  <h1>Prospective Students</h1>
  <p>There are multiple open research positions in my Lab.</p>
  <p>Topics of interest include:</p>
  <ul>
    <li><strong>3D Generative Models</strong></li>
    <li><strong>Physics-based Human Motion Generation</strong></li>
    <li><strong>Neural Representations for Robotics</strong></li>
    <li><strong>Other topics in Graphics and Vision</strong></li>
  </ul>
  <p>If you are interested in exploring research opportunities in our lab—whether as an intern, PhD candidate, visiting PhD, or postdoctoral researcher—please feel free to reach out to me without hesitation. I would be delighted to discuss potential positions with you!</p>
</section>

<section id="GroupMembers">
  <h1>Group Members</h1>
  <p>PhD Students:</p>
  <ul>
    <li><strong>Yixuan Zha (2025, Ph.D.)</strong></li>
    <li><strong>Tingsong Lu (2023, Ph.D., Co-supervised)</strong></li>
  </ul>
  <p>Master Students:</p>
  <ul>
    <li><strong>Fangyun Xu (2025, Master)</strong></li>
    <li><strong>Guangchen Xu (2025, Master)</strong></li>
    <li><strong>Shuhua Xu (2025, Master)</strong></li>
    <li><strong>Yuhan Cui (2024, Master)</strong></li>
    <li><strong>Zesen Huang (2024, Master)</strong></li>
    <li><strong>Jundong Qiu (2024, Master)</strong></li>
    <li><strong>Jiajun Chen (2024, Master)</strong></li>
    <li><strong>Shikun Zhou (2023, Master)</strong></li>
    <li><strong>Quan Wang (2023, Master)</strong></li>
    <li><strong>Lihui Wu (2023, Master)</strong></li>
    <li><strong>Yang Xiao (2022, Master)</strong></li>
    <li><strong>Binsong Zuo (2022, Master)</strong></li>
    <li><strong>Mingfang Mao (2022, Master)</strong></li>
    <li><strong>Wenxu Guo (2021, Master)</strong></li>
    <li><strong>Feng Li (2021, Master)</strong></li>
  </ul>
</section>

<section id="Achievements">
  <h1>Research Achievements</h1>
 <!-- <hr> <!-- 使用 <hr> 添加水平分隔线 -->
  <p>
    In recent years, I have published over 10 academic journal and conference papers in prestigious international venues, including:
  </p>
  <ul>
    <li><strong>ACM SIGGRAPH</strong></li>
    <li><strong>ACM Transactions on Graphics (TOG)</strong></li>
    <li><strong>IEEE Transactions on Visualization and Computer Graphics (TVCG)</strong></li>
  </ul>
  <p>
    I have also been granted <strong>more than 10 invention patents</strong>.
  </p>
  <p>
    Additionally, I have led one project funded by the <strong>National Natural Science Foundation</strong>,
    one project funded by the <strong>Jiangxi Provincial Natural Science Foundation</strong>,
    and <strong>three other provincial-level projects</strong>.
  </p>
 

<section id="Services">
<h1>Academic and Professional Services</h1>
<ul>
  <li>Reviewer for journals including TVCG, TMM, VC, CAVW, and CG.</li>
  <li>Reviewer for academic conferences such as SIGGRAPH Asia, Eurographics, SCA, and CGI.</li>
  <li>Program Committee Member for the CGI2024/2025 academic conference.</li>
  <li>Member of the Virtual Reality Special Committee of the China Society of Image and Graphics.</li>
  <li>Expert in the Jiangxi Province Forensic Appraisal Expert Database.</li>
  <li>Chairperson of the Audio-Visual Materials Appraisal Special Committee of the Jiangxi Province Forensic Appraisal Association.</li>
</ul>
</section>

<section id="Project">
<h1>Research Projects</h1>
<ul>
    <li>
    Key Program of the Natural Science Foundation of Jiangxi Province, 
    <strong><em>"Research on Full-Body Pose Reconstruction and Motion Generation of Digital Humans Based on Sparse Data in Virtual Reality Scenarios"</em></strong>, 
    Project No. 20252BAC250014, Duration: June 2025 – June 2028.
  </li>
  <li>
    National Natural Science Foundation Project of China, 
    <strong><em>"Research on Data-Driven Flexible Deformation and Flight Simulation of Butterflies"</em></strong>, 
    Project No. 62262024, Duration: January 2023 - December 2026.
  </li>
  <li>
    Jiangxi Provincial Natural Science Foundation Project, 
    <strong><em>"Research on Aerodynamics-Based Dynamic Simulation and Posture Generation of Flying Insects"</em></strong>, 
    Project No. 20232BAB202023, Duration: July 2023 - July 2026.
  </li>
  <li>
    Jiangxi Provincial Department of Education Science and Technology Research Project, 
    <strong><em>"Simulation Research on the Impact of Physical Environment on High-Density Crowds"</em></strong>, 
    Project No. GJJ201511, Duration: January 2022 - December 2023.
  </li>
  <li>
    Jiangxi Provincial Department of Education Science and Technology Research Project, 
    <strong><em>"Macroscopic Modeling and Evaluation Methods for Large-Scale Crowds Based on Fluid Dynamics"</em></strong>, 
    Project No. GJJ207109, Duration: January 2021 - December 2022.
  </li>
  <li>
    Jiangxi Provincial Graduate Innovation Fund Project, 
    <strong><em>"Research on Deformation Animation of Biological Groups"</em></strong>, 
    Jiangxi Provincial Department of Education, 2018.
  </li>
</ul>




  
<!--Invention Patent
------
1. **Qiang Chen**, Wenxu Guo, Yuming Fang, et al., **"*A Virtual Bee Flight Control Method*"**. September 2023, China, Patent No. 202311148614.X (Invention Patent, Authorized).
2. **Qiang Chen**, Feng Li, Yuming Fang, et al., **"*A Skeleton-Driven Simulation Method for Wing Deformation of Flying Insects*"**. July 2023, China, Patent No. 202310876202.1 (Invention Patent, Authorized).
3. **Qiang Chen**, Feng Li, Tingsong Lu, Yuming Fang, Wenxu Guo, **"*Data Processing Method and System for Motion Capture of Lepidopteran Insects*"**, July 2022, China, Patent No. 202210900490.5 (Invention Patent, Authorized).
4. Guoliang Luo, Tingsong Lu, **Qiang Chen**, et al., **"*Simulation and Control Method, System, and Readable Storage Medium for Lepidopteran Insects*"**, May 2021, China, Patent No. 202110508065.7 (Invention Patent, Authorized).
5. **Qiang Chen**, Guoliang Luo, Yang Tong, **"*Polarization Linear Wave Simulation Method, System, and Readable Storage Medium for High-Density Crowds*"**, November 2020, China, Patent No. 202010637889.X (Invention Patent, Authorized).
6. Guoliang Luo, **Qiang Chen**, et al., **"*A Large-Scale 3D Face Synthesis System with Sample Similarity Suppression*"**, June 2020, China, Patent No. 202010612054.9 (Invention Patent, Authorized).
-->

<section id="Publications">
<h1>Publications</h1>

<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/CAVW_SinMDGan" 
           alt="SinMDGan: A Hybrid Deep Learning Framework for Single Motion Synthesis Using Diffusion-GAN Models"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">SinMDGan: A Hybrid Deep Learning Framework for Single Motion Synthesis Using Diffusion-GAN Models</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Binsong Zuo, Tingsong Lu, Yuming Fang, Xiaolu Mu, Chao Cai, Xiaogang Jin. SinMDGan: A Hybrid Deep Learning Framework for Single Motion Synthesis Using Diffusion‐GAN Models[J]. Computer Animation and Virtual Worlds, 2026, 37(1): e70091.
      </p>
      <a href="https://onlinelibrary.wiley.com/doi/10.1002/cav.70091" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>       
    </div>
  </div>
</div>

<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/HM and EM data analysis chart1.png" 
           alt="A Multimodal Emotional Response Dataset from 360° VR Videos Across Different Age Groups"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">MERD-360VR: A Multimodal Emotional Response Dataset from 360° VR Videos Across Different Age Groups</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Shikun Zhou, Yuming Fang, Dan Luo, and Tingsong Lu. 2025. MERD-360VR: A Multimodal Emotional Response Dataset from 360° VRVideos Across Different Age Groups. In Proceedings of the 27th International  Conference on Multimodal Interaction (ICMI ’25), October 13–17, 2025, Canberra, ACT, Australia. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3716553.3750777.
      </p>
      <a href="/assets/paper/MERD-360VR_ICMI2025.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <a href="https://drive.google.com/open?id=1aI9KqXMiDMDnbweoKTGnKSsx6FGru0tb&usp=drive_fs" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      <!--
      <a href="https://www.youtube.com/watch?v=_WH2GpYKIZg" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>     
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>      
       -->
    </div>
  </div>
</div>

<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/Ast.png" 
           alt="Decoding Emotions: How Ocular Features Influence Perception of Emotional Intensity in Virtual Characters"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">Decoding Emotions: How Ocular Features Influence Perception of Emotional Intensity in Virtual Characters</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Mingfang Mao, Tingsong Lu, Shikun Zhou, Yuming Fang. Computer Graphics International 2025 LNCS Proceedings Paper. 2025: 7.
      </p>
      <a href="/assets/paper/Paper40_Decoding Emotions_ How Ocular Features Influence Perception of Emotional Intensity in Virtual Characters.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <!--
      <a href="https://www.youtube.com/watch?v=_WH2GpYKIZg" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>     
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="#" 
         class="paper-link" onclick="return false;">[Dataset]</a>
       -->
    </div>
  </div>
</div>
  
  
  
  <div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/aaa.png" 
           alt="Real-time Wing Deformation Simulations for Flying Insects"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">Real-time Wing Deformation Simulations for Flying Insects</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Zhigang Deng, Feng Li, Yuming Fang, Tingsong Lu, Yang Tong, Yifan Zuo. ACM SIGGRAPH 2024 Conference Papers. 2024: 1-11.
      </p>
      <a href="/assets/paper/Real-time Wing Deformation Simulations for Flying Insects.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <a href="https://www.youtube.com/watch?v=_WH2GpYKIZg" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
     <!--
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="#" 
         class="paper-link" onclick="return false;">[Dataset]</a>
       -->
    </div>
  </div>
</div>



<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/A Bio-inspired Model for Bee Simulations.jpg" 
           alt="A Bio-inspired Model for Bee Simulations"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">A Bio-inspired Model for Bee Simulations</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Wenxu Guo, Yuming Fang, Yang Tong, Tingsong Lu, Xiaogang Jin, and Zhigang Deng. IEEE Transactions on Visualization & Computer Graphics, 2025, 31(04): 2073-2085.
      </p>
      <a href="/assets/paper/A Bio-inspired Model for Bee Simulations.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <a href="https://www.youtube.com/watch?v=fvRYbIotM4Y&t=15s" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
          <!--
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="#" 
         class="paper-link" onclick="return false;">[Dataset]</a>
       -->
    </div>
  </div>
</div>



<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/safeDestination.png" 
           alt="Crowd evacuation simulation in flowing fluids"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">Crowd evacuation simulation in flowing fluids</h3>
      <p class="paper-authors">
        Xunjin Zou, Yunqing Ye, Zhenming Zhu, <strong>Qiang Chen*</strong>. Computer Animation and Virtual Worlds, Wiley, 2023, 32(1): e2161. 
      </p>
      <a href="/assets/paper/Crowd evacuation simulation in flowing fluids.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <!--
      <a href="/assets/Video/Video.mp4" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="/assets/Dataset/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      -->
    </div>
  </div>
</div>


<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/insectMoCap.png" 
           alt="A Practical Method for Butterfly Motion Capture"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">A Practical Method for Butterfly Motion Capture</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Tingsong Lu, Yang Tong, Yuming Fang, Zhigang Deng. Proceedings of the 15th ACM SIGGRAPH Conference on Motion, Interaction and Games. 2022: 1-9
      </p>
      <a href="/assets/paper/A Practical Method for Butterfly Motion Capture.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>

      
      <a href="/assets/Video/Demo_MIG2022_A Practical Method for Butterfly Motion Capture.mp4" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <!--<a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
          -->
      <a href="https://github.com/QiangChen-CG/butterflymotiondatasets" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
       
    </div>
  </div>
</div>


<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/ButterflyFlightSimulation.png" 
           alt="A Practical Model for Realistic Butterfly Flight Simulation"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">A Practical Model for Realistic Butterfly Flight Simulation</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Tingsong Lu, Yang Tong, Guoliang Luo, Xiaogang Jin, Zhigang Deng. ACM Transactions on Graphics (TOG), 2022, 41(3): 1-12.
      </p>
      <a href="/assets/paper/A Practical Model for Realistic Butterfly Flight Simulation.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <a href="https://www.youtube.com/watch?v=_6cuoTipGAs&t=52s" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <!--
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="/assets/Dataset/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      -->
    </div>
  </div>
</div>


<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/A linear wave propagation‐based simulation model for dense and polarized crowds.jpg" 
           alt="A linear wave propagation‐based simulation model for dense and polarized crowds"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">A linear wave propagation‐based simulation model for dense and polarized crowds</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Guoliang Luo, Yang Tong, Xiaogang Jin, Zhigang Deng. Computer Animation and Virtual Worlds, 2021, 32(1): e1977. 
      </p>
      <a href="/assets/paper/A linear wave propagation‐based simulation model for dense and polarized crowds.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <a href="https://www.youtube.com/watch?v=ak-AZjRzT20&t=5s" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <!--
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="/assets/Dataset/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      -->
    </div>
  </div>
</div>


<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/3Dface.png" 
           alt="Geometry Sampling for 3D Face Generation via DCGAN"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">Geometry Sampling for 3D Face Generation via DCGAN</h3>
      <p class="paper-authors">
        Guoliang Luo, Xin Zhao, Yang Tong, <strong>Qiang Chen</strong>, Zhiliang Zhu, Haopeng Lei and Juncong Lin. 2020 International Joint Conference on Neural Networks (IJCNN). 2020
      </p>
      <a href="/assets/paper/Geometry Sampling for 3D Face Generation via DCGAN.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <!--
      <a href="/assets/Video/Video.mp4" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="/assets/Dataset/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      -->
    </div>
  </div>
</div>

<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/ActionConsistencyofCasting.png" 
           alt="The Action Consistency of Casting in Virtual Environment"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">The Action Consistency of Casting in Virtual Environment</h3>
      <p class="paper-authors">
        Guoliang Luo, Zeiwei Guan, Guoming Xiong, <strong>Qiang Chen</strong>, Meihua Xiao, and Shihui Guo. 2020 International Conference on Virtual Reality and Visualization (ICVRV). 2020.8
      </p>
      <a href="/assets/paper/The Action Consistency of Casting in Virtual Environment.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
     <!--
      <a href="/assets/Video/Video.mp4" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="/assets/Dataset/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      -->
    </div>
  </div>
</div>

<div class="paper-list">
  <div class="paper-item">
    <!-- 图片部分 -->
      <img src="/assets/images/Shape-constrained flying insects animation.jpg" 
           alt="Shape-constrained flying insects animation"
           style="width: 160px; height: 120px; margin-right: 20px;"
           >
    <!-- 文章内容部分 -->
    <div class="paper-content">
      <h3 class="paper-title">Shape-constrained flying insects animation</h3>
      <p class="paper-authors">
        <strong>Qiang Chen</strong>, Guoliang Luo, Yang Tong, Xiaogang Jin, Zhigang Deng. Computer Animation and Virtual Worlds, Wiley, 2019, 30(3-4): e1920.
      </p>
      <a href="/assets/paper/Shape-constrained flying insects animation.pdf" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[PDF]</a>
      <a href="https://www.youtube.com/watch?v=4SfVb3ZEQAw" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Video]</a>
      <!--
      <a href="/assets/Code/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Code]</a>
      <a href="/assets/Dataset/1" 
         class="paper-link" target="_blank" rel="noopener noreferrer">[Dataset]</a>
      -->
    </div>
  </div>
</div>
